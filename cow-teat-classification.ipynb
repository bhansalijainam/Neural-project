{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cow Teat Image Classification\n",
        "\n",
        "This notebook implements a custom CNN to classify cow teat images using PyTorch. \n",
        "It includes improvements such as Batch Normalization, Dropout, and specific data loading logic for the project's split dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "\n",
        "# ============ CONFIG ============\n",
        "BASE_DIR = os.getcwd()\n",
        "TRAIN_DIRS = [\n",
        "    os.path.join(BASE_DIR, \"Train_1\", \"Score_1\"), # Class 0\n",
        "    os.path.join(BASE_DIR, \"Train_1\", \"Score_2\"), # Class 1\n",
        "    os.path.join(BASE_DIR, \"Train_2\", \"Score_3\"), # Class 2\n",
        "    os.path.join(BASE_DIR, \"Train_2\", \"Score_4\"), # Class 3\n",
        "]\n",
        "TEST_DIR = os.path.join(BASE_DIR, \"Test-2\")\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ DATASET CLASSES ============\n",
        "\n",
        "class SingleClassDataset(Dataset):\n",
        "    \"\"\"Dataset for a single folder representing one class.\"\"\"\n",
        "    def __init__(self, root_dir, class_label, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.class_label = class_label\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            image = Image.new('RGB', (224, 224))\n",
        "            \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, self.class_label\n",
        "\n",
        "class CheckTestDataset(Dataset):\n",
        "    \"\"\"Test dataset that parses class from filename (e.g. ..._C1_...).\"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted([f for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        # Parse label: Look for _C1_, _C2_, etc.\n",
        "        match = re.search(r'_C(\\d)_', img_name)\n",
        "        if match:\n",
        "            class_num = int(match.group(1))\n",
        "            label = class_num - 1 # 1-based to 0-based\n",
        "        else:\n",
        "            # print(f\"Warning: Could not parse class from {img_name}, defaulting to 0\")\n",
        "            label = 0\n",
        "            \n",
        "        return image, label, img_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ TRANSFORMS ============\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ============ DATA LOADING ============\n",
        "\n",
        "train_datasets = []\n",
        "for i, directory in enumerate(TRAIN_DIRS):\n",
        "    if os.path.exists(directory):\n",
        "        print(f\"Loading Class {i} from {directory}\")\n",
        "        ds = SingleClassDataset(directory, class_label=i, transform=train_transform)\n",
        "        train_datasets.append(ds)\n",
        "        print(f\"  Found {len(ds)} images.\")\n",
        "    else:\n",
        "        print(f\"WARNING: Directory not found: {directory}\")\n",
        "\n",
        "if not train_datasets:\n",
        "    print(\"No training data found! Check paths.\")\n",
        "else:\n",
        "    full_train_dataset = ConcatDataset(train_datasets)\n",
        "    # Set num_workers=0 for macOS compatibility\n",
        "    train_loader = DataLoader(full_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "\n",
        "if os.path.exists(TEST_DIR):\n",
        "    test_dataset = CheckTestDataset(TEST_DIR, transform=test_transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    print(f\"Loading Test data from {TEST_DIR}\")\n",
        "    print(f\"  Found {len(test_dataset)} images.\")\n",
        "else:\n",
        "    print(f\"WARNING: Test directory not found: {TEST_DIR}\")\n",
        "    test_loader = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ MODEL ============\n",
        "\n",
        "class ImprovedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedNet, self).__init__()\n",
        "        # 1. Conv Block\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        # 2. Conv Block\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        # 3. Conv Block\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        # 4. Conv Block\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        # 5. Conv Block\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Fully Connected\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
        "        self.drop1 = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.drop2 = nn.Dropout(0.2)\n",
        "        self.fc3 = nn.Linear(512, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x)))) # 112\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x)))) # 56\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x)))) # 28\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x)))) # 14\n",
        "        x = self.pool(F.relu(self.bn5(self.conv5(x)))) # 7\n",
        "        \n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.drop2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ TRAINING ============\n",
        "\n",
        "model = ImprovedNet().to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    if train_loader:\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "        \n",
        "        scheduler.step()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        loss_values.append(epoch_loss)\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {epoch_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Loss\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(loss_values, 'b-o', label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'training_loss.png'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ EVALUATION ============\n",
        "\n",
        "if test_loader:\n",
        "    print(\"Evaluating on Test Set...\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, filenames in test_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    \n",
        "    # Save Model\n",
        "    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'model.pt'))\n",
        "    print(f\"Model saved to {os.path.join(OUTPUT_DIR, 'model.pt')}\")\n",
        "    \n",
        "    # Predictions CSV\n",
        "    test_files = test_dataset.image_files\n",
        "    df = pd.DataFrame({'Image': test_files, 'True Label': all_labels, 'Predicted': all_preds})\n",
        "    df.to_csv(os.path.join(OUTPUT_DIR, 'predictions.csv'), index=False)\n",
        "    print(\"Predictions saved to outputs/predictions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Links\n",
        "- [Project Paper](./Image%20classification%20using%20CNN%20with%20pytorch.pdf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}