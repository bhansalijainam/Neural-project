{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "009e8fc2",
      "metadata": {},
      "source": [
        "# 1. Build your own convolutional neural network using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "475fc40e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ed99ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ CONFIG - Update these paths for your environment ============\n",
        "DATA_ROOT = os.path.join(os.getcwd(), \"data\")  # Or set absolute path: \"/path/to/Cowtestdata\"\n",
        "TRAIN_PATH = os.path.join(DATA_ROOT, \"Train\")\n",
        "TEST_PATH = os.path.join(DATA_ROOT, \"Test\")\n",
        "OUTPUT_DIR = os.path.join(os.getcwd(), \"outputs\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "63056306",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c45b84",
      "metadata": {},
      "source": [
        "# 2. Train your model using cow teat datasets (you may need to use  Google Colab (or Kaggle) with GPU to train your code) \n",
        "\n",
        "### (1) use torchvision.datasets.ImageFolder for the training dataset\n",
        "### (2) use custom dataloader for test dataset (return image tensor and file name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b271ba16",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomTestDataset(Dataset):\n",
        "    \"\"\"Custom test dataset that returns image tensor, label, and file name.\"\"\"\n",
        "    IMG_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "\n",
        "    def __init__(self, root_dir, transforms=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.file_names = sorted([f for f in os.listdir(root_dir)\n",
        "                                  if os.path.splitext(f)[1].lower() in self.IMG_EXTENSIONS])\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_name = self.file_names[idx]\n",
        "        file_path = os.path.join(self.root_dir, file_name)\n",
        "        image = Image.open(file_path).convert('RGB')\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        # Parse label from filename (e.g. c1_xxx.jpg -> 1)\n",
        "        label = int(file_name.split(\"_\")[0][1:])\n",
        "        return image, label, file_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "44fdd8a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define the transforms for the test dataset\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "44a35308",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the training and test datasets\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=TRAIN_PATH, transform=train_transform)\n",
        "test_dataset = CustomTestDataset(root_dir=TEST_PATH, transforms=test_transform)\n",
        "\n",
        "# Define the dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f63262f",
      "metadata": {},
      "source": [
        "# 3. Evaluate your model using the developed software"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ab66ddc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, loss: 1.139\n",
            "Epoch 2, loss: 0.970\n",
            "Epoch 3, loss: 0.932\n",
            "Epoch 4, loss: 0.917\n",
            "Epoch 5, loss: 0.902\n",
            "Epoch 6, loss: 0.899\n",
            "Epoch 7, loss: 0.897\n",
            "Epoch 8, loss: 0.884\n",
            "Epoch 9, loss: 0.859\n",
            "Epoch 10, loss: 0.853\n"
          ]
        }
      ],
      "source": [
        "# Reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Device (GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize the model and optimizer\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "loss_values = []\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    loss_values.append(epoch_loss)\n",
        "    print(\"Epoch %d, loss: %.3f\" % (epoch + 1, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a626823",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training loss curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(loss_values, 'b-o', linewidth=2, markersize=6)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'training_loss.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Evaluation\n",
        "predicted_values = []\n",
        "all_filenames = []\n",
        "all_labels = []\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels, filenames in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.cpu() == labels).sum().item()\n",
        "        predicted_values.extend(predicted.cpu().tolist())\n",
        "        all_filenames.extend(filenames)\n",
        "        all_labels.extend(labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "20354638",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accuracy and per-class metrics\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(all_labels, predicted_values)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification Report:\")\n",
        "class_names = train_dataset.classes if hasattr(train_dataset, 'classes') else ['class_0', 'class_1', 'class_2', 'class_3']\n",
        "print(classification_report(all_labels, predicted_values, target_names=class_names))\n",
        "\n",
        "# Save predictions CSV\n",
        "df = pd.DataFrame({'Test File': all_filenames, 'True Label': all_labels, 'Predicted': predicted_values})\n",
        "df.to_csv(os.path.join(OUTPUT_DIR, 'predictions.csv'), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0f80f1b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'model.pt'))\n",
        "print(f\"Model saved to {OUTPUT_DIR}/model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9b43642",
      "metadata": {},
      "source": [
        "![project.PNG](attachment:project.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5846bc",
      "metadata": {},
      "source": [
        "# 4. Compare results with [SCTL paper](https://www.mdpi.com/2076-2615/12/7/886/htm). Requirement: performance is better than VGG16: 66.8%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe6339c2",
      "metadata": {},
      "source": [
        "We could achive only 61.842 %"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f12835",
      "metadata": {},
      "source": [
        "# 5. Write a four-page paper report using the shared LaTex template. Upload your paper to ResearchGate or Arxiv, and put your paper link here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e94e48",
      "metadata": {},
      "source": [
        "https://github.com/bhansalijainam/Neural-project/blob/main/Image%20classification%20using%20CNN%20with%20pytorch.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3ad390d",
      "metadata": {},
      "source": [
        "Uploaded on github after review will upload on research gate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f476372c",
      "metadata": {},
      "source": [
        "# 6. Grading rubric\n",
        "\n",
        "(1). Code ------- 20 points (you also need to upload your final model as a pt file)\n",
        "\n",
        "(2). Grammer ---- 20 points\n",
        "\n",
        "(3). Introduction & related work --- 10 points\n",
        "\n",
        "\n",
        "(4). Method  ---- 20 points\n",
        "\n",
        "(5). Results ---- 20 points\n",
        "\n",
        "     > = 66.8% -->10 points\n",
        "     < 40 % -->0 points\n",
        "     >= 40 % & < 66.8% --> 0.3731 point/percent\n",
        "     \n",
        "\n",
        "(6). Discussion - 10 points"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b95372b",
      "metadata": {},
      "source": [
        "https://drive.google.com/file/d/1vFQYmbQCun5k5K5LNLWxjNQuKT-i2ObU/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3305f6b6",
      "metadata": {},
      "source": [
        "this is the link of my weight shared over here due to file size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44aac49d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
